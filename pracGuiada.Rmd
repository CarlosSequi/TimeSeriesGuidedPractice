---
title: "practicaGuiada"
output: pdf_document
---


Cargamos la biblioteca para series temporales.
```{r}
library(tseries)
```

Leemos los datos de la serie
```{r}
serie = scan("pasajeros_1949_1959.dat")
```

Dividimos los datos en entrenamiento y test. Dejamos para ello el último año para la comprobación de la validez del modelo, y el resto lo usamos como train.
```{r}
NTest = 12 # cantidad de datos a usar como test
NPred = 12 # cantidad de predicciones que queremos realizar 
serie.ts = ts(serie, frequency = 12) # creamos el objeto serie temporal suponiendo una estacionalidad de 12 meses
plot(decompose(serie.ts))
```

Observamos aquí: \\
-observed: los valores de la serie\\
-trend: la tendencia calculada mediante filtros\\
-seasonal: estacionalidad en la que cada 12 instantes de tiempo se repite la serie\\
-random: lo que queda de la serie una vez eliminadas tendencia y estacionalidad\\

Como observamos en random, la varianza es alta, lo que puede dar problemas en un futuro para la estacionariedad,
ya que como sabemos, una serie con estacionariedad no varía en media ni en varianza. Para ello, a la serie inicial
le calculamos el logaritmo de la serie (calculamos el logaritmo tanto a los datos como a la serie temporal):
```{r}
serie.ts.log = log(serie.ts)
serie.log = log(serie)
plot(decompose(serie.ts.log))
```

Como observamos ahora, la varianza consta de menor variación a lo largo del tiempo, lo que en un futuro provocará que no tengamos problemas a la hora de calcular la estacionariedad.

Aplicando decompose sobre los datos podemos observar como los valores de cada mes en el atributo seasonal son exactamente los mismos, lo que nos hará falta para calcular la componente estacional y restarselo a la serie.
```{r}
decompose(serie.ts.log)
```


Procedemos a la división de los datos en train y test
```{r}
serieTr = serie.log[1:(length(serie.log)-NTest)] # tomamos todos los valores de la serie
                                                 # como train excepto los 12 últimos
tiempoTr = 1:length(serieTr) # instantes de tiempo de esta serie train

# mismo proceso para la serie de test...
serieTs = serie.log[(length(serie.log)-NTest+1):length(serie)]
tiempoTs = (tiempoTr[length(tiempoTr)]+1):(tiempoTr[length(tiempoTr)]+NTest)
```


Representamos la serie de entrenamiento y la linea de la serie de test en rojo con los parametros necesarios para que salga de forma correcta dentro de los límites de la gráfica y en el lugar adecuado.
```{r}
plot.ts(serieTr, xlim=c(1, tiempoTs[length(tiempoTs)]))
lines(tiempoTs, serieTs, col="red")
```


A continuación prodecemos a modelar la tendencia. 
Parece ser que la tendencia es lineal y creciente, por lo que tendrá la forma de:\\
serie = parametroA*tiempo + parametroB.\\
Con la funcion lm calculamos esos dos parametros para modelar dicha tendencia.
```{r}
parametros.H1 = lm(serieTr ~tiempoTr)
parametros.H1
```

Intercept es el termino independiente (parametroB) y el otro es el que multiplica al tiempo para poder calcular la serie (parametroA). Para modelar la tendencia usamos la fórmula descrita antes:
```{r}
tendEstimadaTr = parametros.H1$coefficients[1] + tiempoTr*parametros.H1$coefficients[2] # tendencia en entrenamiento
tendEstimadaTs = parametros.H1$coefficients[1] + tiempoTs*parametros.H1$coefficients[2] # tendencia en test
```

Comprobamos de forma visual si la tendencia se ajusta al modelo que tenemos de la serie temporal.
```{r}
plot.ts(serieTr, xlim=c(1, tiempoTs[length(tiempoTs)]))
lines(tiempoTs, serieTs, col="red")
lines(tiempoTr, tendEstimadaTr, col = "blue")
lines(tiempoTs, tendEstimadaTs, col = "green")
```


Validamos a continuación de forma estadística que el modelo lineal creado sea correcto. Para ellos hemos de comprobar que los errores a lo largo del rango de la serie tanto en entrenamiento como en test son normales, es decir, que se distribuyen mediante distribución normal a lo largo de todo el tiempo.\\

Aplicamos el test de normalidad de Jarque Bera para comprobar la normalidad en los errores tanto en los residuos del entrenamiento como en los del test, calculados como la tendencia estimada en test menos la serie temporal.


```{r}
JB.tr = jarque.bera.test(parametros.H1$residuals)
JB.ts = jarque.bera.test(tendEstimadaTs-serieTs)
JB.tr
JB.ts
```

Asumiendo confianza del 95% podemos asumir que no hay diferencia significativa de los datos de error con respecto a los de una distribución normal ni en train ni en test (ya que ambos p-value son mayores a 0.05).\\

Comparamos las medias de error para comprobar si el error producido en la parte de train es equivalente al producido en la parte de test. Aplicamos el Test de Student para comparar dos distribuciones de datos diferentes (mediante sus medias).
```{r}
TT = t.test(c(parametros.H1$residuals, tendEstimadaTs-serieTs))
TT
```

El p-value nos indica que esta distribución de errores es de media cero (casi: 0.007), y que no hay una desviación significativa con respecto a esta media, por tanto ambos errores de test y entrenamiento tienen la misma media y el modelo lineal es válido, por lo que la tendencia calculada es correcta. Procedemos por tanto a eliminar la tendencia de las series iniciales de entrenamiento y test.

```{r}
serieTr.SinTend = serieTr - tendEstimadaTr
serieTs.SinTend = serieTs - tendEstimadaTs

# comprobamos como queda:
plot.ts(serieTr.SinTend, xlim=c(1, tiempoTs[length(tiempoTs)]))
lines(tiempoTs, serieTs.SinTend, col="red")
```





































